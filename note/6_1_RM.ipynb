{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d0fa4e-7bde-483b-9bc5-cadc093e3eb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# # 6_1_Tuning parameters of RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947610f6-0840-44e2-853c-3df88906505f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4946b4fd-f093-4e80-966e-7997f9232fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load the files\n",
    "\n",
    "X_train = pd.read_csv('../data/x_y_data/SMOTE/X_resampled.csv')\n",
    "y_train = pd.read_csv('../data/x_y_data/SMOTE/y_resampled.csv')\n",
    "X_test = pd.read_csv('../data/x_y_data/SMOTE/X_test.csv')\n",
    "y_test = pd.read_csv('../data/x_y_data/SMOTE/y_test.csv')\n",
    "data = pd.read_csv('../data/cleaned_data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31b770e0-43fd-405f-a0f3-a82d2d3bc83c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "1    4130\n",
       "0    4130\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.loc[y_train['churn'] == 'Yes', 'churn'] = 1\n",
    "y_train.loc[y_train['churn'] == 'No', 'churn'] = 0\n",
    "y_train['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b3e4ed0-83ac-43ee-93ef-4074bd5fd44a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['churn'] =y_train['churn'].astype('int64')\n",
    "y_train['churn'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0552de7-37c5-40af-97ab-3519b92c31c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0    1033\n",
       "1     374\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.loc[y_test['churn'] == 'Yes', 'churn'] = 1\n",
    "y_test.loc[y_test['churn'] == 'No', 'churn'] = 0\n",
    "y_test['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8101933-b182-4679-a4a9-a05c0b08f3cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['churn'] =y_test['churn'].astype('int64')\n",
    "y_test['churn'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c00c71c1-988a-4769-ba45-9130db4684b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439bb0a45da14812888acaf39458499c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.578, test=0.551) total time=   0.8s\n",
      "[CV 5/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.618, test=0.535) total time=   0.8s\n",
      "[CV 4/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.585, test=0.594) total time=   1.4s\n",
      "[CV 2/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.578, test=0.551) total time=   1.2s\n",
      "[CV 5/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.584, test=0.584) total time=   1.4s\n",
      "[CV 3/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.587, test=0.567) total time=   1.0s\n",
      "[CV 4/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.594) total time=   1.4s\n",
      "[CV 2/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.579, test=0.545) total time=   1.1s\n",
      "[CV 3/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.590, test=0.582) total time=   1.9s\n",
      "[CV 1/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.617, test=0.538) total time=   1.4s\n",
      "[CV 2/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.588, test=0.548) total time=   2.0s\n",
      "[CV 5/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.586, test=0.584) total time=   2.6s\n",
      "[CV 1/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.627, test=0.533) total time=   2.9s\n",
      "[CV 4/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.583, test=0.596) total time=   1.9s\n",
      "[CV 2/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.588, test=0.552) total time=   2.4s\n",
      "[CV 5/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.579, test=0.580) total time=   0.9s\n",
      "[CV 3/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.593, test=0.580) total time=   1.8s\n",
      "[CV 1/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.626, test=0.534) total time=   1.5s\n",
      "[CV 4/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.587, test=0.591) total time=   1.6s\n",
      "[CV 5/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.585, test=0.586) total time=   1.4s\n",
      "[CV 3/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.586, test=0.573) total time=   1.2s\n",
      "[CV 4/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.586, test=0.592) total time=   1.9s\n",
      "[CV 2/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.579, test=0.545) total time=   1.3s\n",
      "[CV 3/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.590, test=0.582) total time=   2.0s\n",
      "[CV 1/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.618, test=0.538) total time=   1.6s\n",
      "[CV 5/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.581, test=0.584) total time=   1.7s\n",
      "[CV 3/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.593, test=0.584) total time=   2.8s\n",
      "[CV 2/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.547) total time=   2.3s\n",
      "[CV 5/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.582, test=0.582) total time=   2.3s\n",
      "[CV 1/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.627, test=0.535) total time=   3.1s\n",
      "[CV 4/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.583, test=0.596) total time=   1.6s\n",
      "[CV 2/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.588, test=0.552) total time=   2.8s\n",
      "[CV 5/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.778, test=0.736) total time=   2.2s\n",
      "[CV 3/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.778, test=0.705) total time=   4.0s\n",
      "[CV 1/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.814, test=0.535) total time=   3.4s\n",
      "[CV 4/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.772, test=0.731) total time=   5.4s\n",
      "[CV 5/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.583, test=0.575) total time=   0.8s\n",
      "[CV 1/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.626, test=0.533) total time=   1.8s\n",
      "[CV 5/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.579, test=0.580) total time=   1.1s\n",
      "[CV 3/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.593, test=0.584) total time=   1.7s\n",
      "[CV 1/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.625, test=0.536) total time=   1.4s\n",
      "[CV 4/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.587, test=0.592) total time=   1.9s\n",
      "[CV 5/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.585, test=0.585) total time=   1.9s\n",
      "[CV 3/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.586, test=0.573) total time=   1.3s\n",
      "[CV 4/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.586, test=0.592) total time=   2.0s\n",
      "[CV 2/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.579, test=0.546) total time=   1.6s\n",
      "[CV 3/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.594, test=0.580) total time=   2.5s\n",
      "[CV 1/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.617, test=0.535) total time=   1.5s\n",
      "[CV 5/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.576, test=0.582) total time=   1.7s\n",
      "[CV 3/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.589, test=0.581) total time=   2.4s\n",
      "[CV 1/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.624, test=0.539) total time=   2.5s\n",
      "[CV 4/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.586, test=0.592) total time=   2.6s\n",
      "[CV 5/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.581, test=0.586) total time=   2.0s\n",
      "[CV 3/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.776, test=0.706) total time=   2.2s\n",
      "[CV 1/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.811, test=0.533) total time=   3.9s\n",
      "[CV 4/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.772, test=0.730) total time=   2.6s\n",
      "[CV 2/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.796, test=0.632) total time=   4.5s\n",
      "[CV 5/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.763, test=0.731) total time=   3.5s\n",
      "[CV 2/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.795, test=0.630) total time=   5.0s\n",
      "[CV 2/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.787, test=0.628) total time=   3.4s\n",
      "[CV 5/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.760, test=0.719) total time=   3.5s\n",
      "[CV 1/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.798, test=0.525) total time=   2.9s\n",
      "[CV 4/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.752, test=0.728) total time=   2.5s\n",
      "[CV 2/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.789, test=0.622) total time=   4.6s\n",
      "[CV 5/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.729, test=0.699) total time=   2.8s\n",
      "[CV 3/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.725, test=0.679) total time=   4.6s\n",
      "[CV 2/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.762, test=0.625) total time=   2.6s\n",
      "[CV 5/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.729, test=0.705) total time=   3.2s\n",
      "[CV 5/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.730, test=0.702) total time=   3.1s\n",
      "[CV 3/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.581, test=0.573) total time=   1.6s\n",
      "[CV 3/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.579) total time=   1.9s\n",
      "[CV 1/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.616, test=0.536) total time=   1.4s\n",
      "[CV 1/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.626, test=0.538) total time=   1.9s\n",
      "[CV 4/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.591, test=0.599) total time=   2.3s\n",
      "[CV 5/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.592, test=0.582) total time=   1.3s\n",
      "[CV 1/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.618, test=0.535) total time=   1.1s\n",
      "[CV 4/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.583, test=0.594) total time=   1.1s\n",
      "[CV 2/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.590, test=0.554) total time=   1.7s\n",
      "[CV 5/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.580, test=0.585) total time=   1.0s\n",
      "[CV 3/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.594, test=0.582) total time=   1.7s\n",
      "[CV 2/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.588, test=0.548) total time=   1.9s\n",
      "[CV 5/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.586, test=0.584) total time=   2.2s\n",
      "[CV 1/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.629, test=0.534) total time=   2.6s\n",
      "[CV 4/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.584, test=0.592) total time=   1.7s\n",
      "[CV 2/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.548) total time=   2.9s\n",
      "[CV 1/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.624, test=0.539) total time=   2.3s\n",
      "[CV 4/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.586, test=0.592) total time=   2.3s\n",
      "[CV 5/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.581, test=0.586) total time=   2.5s\n",
      "[CV 3/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.584, test=0.568) total time=   1.6s\n",
      "[CV 4/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.586, test=0.591) total time=   2.1s\n",
      "[CV 2/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.799, test=0.626) total time=   2.5s\n",
      "[CV 5/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.779, test=0.724) total time=   2.9s\n",
      "[CV 3/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.768, test=0.707) total time=   2.5s\n",
      "[CV 4/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.771, test=0.726) total time=   3.4s\n",
      "[CV 2/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.792, test=0.623) total time=   3.3s\n",
      "[CV 3/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.761, test=0.705) total time=   4.5s\n",
      "[CV 5/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.768, test=0.724) total time=   4.3s\n",
      "[CV 1/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.798, test=0.525) total time=   4.3s\n",
      "[CV 4/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.756, test=0.731) total time=   2.0s\n",
      "[CV 2/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.785, test=0.628) total time=   2.9s\n",
      "[CV 5/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.753, test=0.717) total time=   2.8s\n",
      "[CV 3/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.755, test=0.690) total time=   4.6s\n",
      "[CV 2/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.762, test=0.625) total time=   4.5s\n",
      "[CV 5/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.729, test=0.705) total time=   3.6s\n",
      "[CV 1/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.771, test=0.533) total time=   3.1s\n",
      "[CV 4/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.723, test=0.703) total time=   2.0s\n",
      "[CV 2/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.764, test=0.617) total time=   3.7s\n",
      "[CV 1/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.626, test=0.538) total time=   2.0s\n",
      "[CV 4/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.591, test=0.599) total time=   2.3s\n",
      "[CV 4/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.590, test=0.594) total time=   1.8s\n",
      "[CV 2/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.584, test=0.547) total time=   1.4s\n",
      "[CV 3/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.583, test=0.594) total time=   0.9s\n",
      "[CV 2/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.590, test=0.556) total time=   1.8s\n",
      "[CV 2/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.589, test=0.552) total time=   1.5s\n",
      "[CV 5/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.588, test=0.580) total time=   1.6s\n",
      "[CV 1/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.627, test=0.531) total time=   1.7s\n",
      "[CV 4/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.585, test=0.597) total time=   1.3s\n",
      "[CV 1/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.629, test=0.534) total time=   2.4s\n",
      "[CV 4/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.585, test=0.597) total time=   1.4s\n",
      "[CV 2/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.589, test=0.553) total time=   2.6s\n",
      "[CV 1/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.624, test=0.536) total time=   2.7s\n",
      "[CV 4/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.588, test=0.594) total time=   2.5s\n",
      "[CV 1/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.627, test=0.535) total time=   2.3s\n",
      "[CV 4/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.583, test=0.596) total time=   1.4s\n",
      "[CV 2/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.588, test=0.552) total time=   3.1s\n",
      "[CV 5/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.576, test=0.582) total time=   1.6s\n",
      "[CV 3/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.581) total time=   2.7s\n",
      "[CV 1/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.813, test=0.528) total time=   3.0s\n",
      "[CV 4/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.778, test=0.738) total time=   4.0s\n",
      "[CV 5/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.776, test=0.729) total time=   3.2s\n",
      "[CV 3/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.759, test=0.706) total time=   3.3s\n",
      "[CV 4/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.763, test=0.719) total time=   4.4s\n",
      "[CV 2/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.786, test=0.630) total time=   2.5s\n",
      "[CV 3/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.757, test=0.696) total time=   3.3s\n",
      "[CV 1/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.800, test=0.521) total time=   2.3s\n",
      "[CV 1/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.797, test=0.521) total time=   2.6s\n",
      "[CV 4/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.760, test=0.723) total time=   3.3s\n",
      "[CV 5/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.758, test=0.723) total time=   3.6s\n",
      "[CV 3/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.725, test=0.683) total time=   2.8s\n",
      "[CV 4/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.728, test=0.711) total time=   4.5s\n",
      "[CV 2/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.765, test=0.620) total time=   2.2s\n",
      "[CV 3/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.725, test=0.686) total time=   2.5s\n",
      "[CV 1/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.771, test=0.535) total time=   1.9s\n",
      "[CV 2/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.762, test=0.625) total time=   3.2s\n",
      "[CV 5/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.729, test=0.705) total time=   3.5s\n",
      "[CV 2/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.593, test=0.556) total time=   2.3s\n",
      "[CV 4/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.586, test=0.592) total time=   1.4s\n",
      "[CV 3/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.592, test=0.581) total time=   2.2s\n",
      "[CV 1/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.625, test=0.539) total time=   1.9s\n",
      "[CV 4/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.596) total time=   2.2s\n",
      "[CV 5/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 75}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.586, test=0.574) total time=   1.9s\n",
      "[CV 2/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.584, test=0.551) total time=   1.4s\n",
      "[CV 1/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.624, test=0.540) total time=   2.0s\n",
      "[CV 4/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.587, test=0.596) total time=   2.9s\n",
      "[CV 1/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.625, test=0.541) total time=   3.3s\n",
      "[CV 4/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.583, test=0.594) total time=   1.6s\n",
      "[CV 2/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.558) total time=   2.3s\n",
      "[CV 5/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.573, test=0.577) total time=   1.5s\n",
      "[CV 3/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.590, test=0.576) total time=   2.5s\n",
      "[CV 1/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.624, test=0.544) total time=   2.3s\n",
      "[CV 4/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.585, test=0.594) total time=   2.1s\n",
      "[CV 5/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.580, test=0.579) total time=   1.7s\n",
      "[CV 3/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.762, test=0.701) total time=   2.0s\n",
      "[CV 1/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.805, test=0.529) total time=   3.3s\n",
      "[CV 4/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.763, test=0.740) total time=   2.1s\n",
      "[CV 1/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.801, test=0.528) total time=   3.7s\n",
      "[CV 5/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.753, test=0.728) total time=   2.7s\n",
      "[CV 2/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.782, test=0.633) total time=   4.5s\n",
      "[CV 1/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.792, test=0.524) total time=   3.1s\n",
      "[CV 1/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.791, test=0.521) total time=   2.3s\n",
      "[CV 5/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.751, test=0.726) total time=   2.3s\n",
      "[CV 3/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.752, test=0.685) total time=   3.5s\n",
      "[CV 1/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.790, test=0.525) total time=   3.0s\n",
      "[CV 4/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.750, test=0.728) total time=   4.1s\n",
      "[CV 5/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.727, test=0.696) total time=   2.6s\n",
      "[CV 3/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.724, test=0.682) total time=   2.4s\n",
      "[CV 4/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.727, test=0.717) total time=   2.8s\n",
      "[CV 2/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.757, test=0.620) total time=   2.2s\n",
      "[CV 3/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.728, test=0.679) total time=   2.9s\n",
      "[CV 2/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.589, test=0.552) total time=   1.3s\n",
      "[CV 5/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.588, test=0.580) total time=   1.8s\n",
      "[CV 4/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.585, test=0.594) total time=   1.4s\n",
      "[CV 2/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.578, test=0.545) total time=   1.0s\n",
      "[CV 3/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.591, test=0.582) total time=   1.4s\n",
      "[CV 1/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.617, test=0.538) total time=   1.1s\n",
      "[CV 1/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.624, test=0.539) total time=   1.9s\n",
      "[CV 4/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.587, test=0.593) total time=   2.2s\n",
      "[CV 5/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.585, test=0.585) total time=   2.0s\n",
      "[CV 3/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.587, test=0.568) total time=   1.7s\n",
      "[CV 4/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.592) total time=   2.5s\n",
      "[CV 2/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.577, test=0.545) total time=   1.6s\n",
      "[CV 3/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.590, test=0.571) total time=   2.2s\n",
      "[CV 1/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.617, test=0.535) total time=   1.5s\n",
      "[CV 2/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.547) total time=   2.6s\n",
      "[CV 1/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.617, test=0.535) total time=   1.6s\n",
      "[CV 2/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.547) total time=   2.1s\n",
      "[CV 4/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.586, test=0.592) total time=   2.7s\n",
      "[CV 3/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.778, test=0.705) total time=   2.9s\n",
      "[CV 2/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.795, test=0.627) total time=   2.5s\n",
      "[CV 2/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.794, test=0.626) total time=   3.4s\n",
      "[CV 5/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.776, test=0.718) total time=   5.5s\n",
      "[CV 1/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.804, test=0.542) total time=   5.4s\n",
      "[CV 4/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.756, test=0.731) total time=   2.1s\n",
      "[CV 2/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.785, test=0.628) total time=   4.2s\n",
      "[CV 5/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.753, test=0.719) total time=   1.9s\n",
      "[CV 3/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.759, test=0.699) total time=   3.0s\n",
      "[CV 2/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.784, test=0.611) total time=   3.7s\n",
      "[CV 5/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.758, test=0.724) total time=   4.9s\n",
      "[CV 1/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.771, test=0.533) total time=   5.1s\n",
      "[CV 4/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.723, test=0.703) total time=   2.0s\n",
      "[CV 2/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.764, test=0.617) total time=   3.1s\n",
      "[CV 5/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.729, test=0.699) total time=   2.3s\n",
      "[CV 3/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.725, test=0.679) total time=   3.7s\n",
      "[CV 4/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.590, test=0.594) total time=   1.9s\n",
      "[CV 2/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.581, test=0.553) total time=   1.4s\n",
      "[CV 3/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.577) total time=   1.8s\n",
      "[CV 1/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.619, test=0.534) total time=   1.4s\n",
      "[CV 5/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.577, test=0.573) total time=   1.4s\n",
      "[CV 3/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.591, test=0.580) total time=   2.2s\n",
      "[CV 3/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.579) total time=   2.0s\n",
      "[CV 1/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.617, test=0.538) total time=   1.8s\n",
      "[CV 2/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.589, test=0.556) total time=   2.4s\n",
      "[CV 4/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.587, test=0.596) total time=   2.8s\n",
      "[CV 5/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.583, test=0.580) total time=   1.8s\n",
      "[CV 3/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.579, test=0.569) total time=   1.4s\n",
      "[CV 4/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.585, test=0.597) total time=   2.0s\n",
      "[CV 2/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.582, test=0.546) total time=   1.5s\n",
      "[CV 3/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.576) total time=   2.2s\n",
      "[CV 1/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.619, test=0.534) total time=   1.3s\n",
      "[CV 1/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.624, test=0.544) total time=   1.8s\n",
      "[CV 4/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.585, test=0.594) total time=   2.1s\n",
      "[CV 3/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.763, test=0.699) total time=   2.6s\n",
      "[CV 2/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.796, test=0.620) total time=   2.0s\n",
      "[CV 3/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.763, test=0.692) total time=   2.9s\n",
      "[CV 1/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.797, test=0.511) total time=   2.2s\n",
      "[CV 1/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.798, test=0.525) total time=   3.6s\n",
      "[CV 4/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.755, test=0.730) total time=   4.5s\n",
      "[CV 4/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.748, test=0.725) total time=   3.1s\n",
      "[CV 3/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.753, test=0.706) total time=   2.4s\n",
      "[CV 4/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.748, test=0.725) total time=   2.9s\n",
      "[CV 2/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.775, test=0.623) total time=   2.1s\n",
      "[CV 2/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.775, test=0.626) total time=   3.0s\n",
      "[CV 1/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.772, test=0.523) total time=   2.5s\n",
      "[CV 1/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.774, test=0.534) total time=   2.7s\n",
      "[CV 4/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.727, test=0.715) total time=   3.7s\n",
      "[CV 5/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.727, test=0.696) total time=   2.8s\n",
      "[CV 3/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.724, test=0.682) total time=   2.2s\n",
      "[CV 4/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.727, test=0.717) total time=   2.9s\n",
      "[CV 5/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.582, test=0.579) total time=   1.9s\n",
      "[CV 3/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.581, test=0.568) total time=   1.3s\n",
      "[CV 4/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.596) total time=   2.0s\n",
      "[CV 2/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.584, test=0.551) total time=   1.7s\n",
      "[CV 3/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.579) total time=   2.5s\n",
      "[CV 1/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.619, test=0.534) total time=   1.7s\n",
      "[CV 1/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.625, test=0.539) total time=   2.0s\n",
      "[CV 4/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.587, test=0.596) total time=   2.3s\n",
      "[CV 5/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.580, test=0.579) total time=   2.0s\n",
      "[CV 3/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.579, test=0.569) total time=   1.5s\n",
      "[CV 4/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.585, test=0.597) total time=   2.1s\n",
      "[CV 2/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.582, test=0.546) total time=   1.3s\n",
      "[CV 3/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.576) total time=   1.7s\n",
      "[CV 1/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.802, test=0.523) total time=   2.0s\n",
      "[CV 2/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.794, test=0.625) total time=   2.6s\n",
      "[CV 5/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.771, test=0.722) total time=   3.4s\n",
      "[CV 2/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.793, test=0.617) total time=   3.7s\n",
      "[CV 4/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.756, test=0.728) total time=   2.7s\n",
      "[CV 3/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.759, test=0.702) total time=   4.5s\n",
      "[CV 3/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.752, test=0.691) total time=   3.1s\n",
      "[CV 4/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.749, test=0.725) total time=   3.9s\n",
      "[CV 1/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.791, test=0.536) total time=   3.6s\n",
      "[CV 4/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.751, test=0.728) total time=   2.2s\n",
      "[CV 2/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.778, test=0.627) total time=   3.8s\n",
      "[CV 5/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.723, test=0.689) total time=   2.1s\n",
      "[CV 3/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.727, test=0.678) total time=   3.4s\n",
      "[CV 1/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.774, test=0.534) total time=   3.0s\n",
      "[CV 4/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.727, test=0.715) total time=   3.6s\n",
      "[CV 5/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.727, test=0.696) total time=   2.8s\n",
      "[CV 5/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.766, test=0.728) total time=   4.6s\n",
      "[CV 3/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.755, test=0.690) total time=   2.2s\n",
      "[CV 4/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.759, test=0.728) total time=   3.5s\n",
      "[CV 2/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.786, test=0.630) total time=   2.0s\n",
      "[CV 3/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.757, test=0.696) total time=   2.5s\n",
      "[CV 1/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.793, test=0.524) total time=   1.9s\n",
      "[CV 1/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.794, test=0.530) total time=   3.7s\n",
      "[CV 4/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.757, test=0.714) total time=   5.0s\n",
      "[CV 5/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.730, test=0.702) total time=   4.3s\n",
      "[CV 3/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.725, test=0.683) total time=   1.9s\n",
      "[CV 5/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.730, test=0.702) total time=   2.4s\n",
      "[CV 2/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.765, test=0.620) total time=   1.9s\n",
      "[CV 3/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.725, test=0.686) total time=   3.2s\n",
      "[CV 1/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.616, test=0.536) total time=   1.7s\n",
      "[CV 5/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.575, test=0.571) total time=   1.5s\n",
      "[CV 3/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.592, test=0.579) total time=   2.3s\n",
      "[CV 2/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.558) total time=   1.9s\n",
      "[CV 5/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.582, test=0.580) total time=   2.2s\n",
      "[CV 1/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.627, test=0.538) total time=   2.4s\n",
      "[CV 4/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.583, test=0.594) total time=   1.3s\n",
      "[CV 2/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.591, test=0.561) total time=   2.9s\n",
      "[CV 5/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.576, test=0.574) total time=   1.6s\n",
      "[CV 3/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.593, test=0.580) total time=   3.2s\n",
      "[CV 2/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.557) total time=   1.9s\n",
      "[CV 5/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.579, test=0.582) total time=   2.4s\n",
      "[CV 1/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.626, test=0.536) total time=   2.6s\n",
      "[CV 4/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.580, test=0.590) total time=   1.5s\n",
      "[CV 2/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.591, test=0.556) total time=   2.2s\n",
      "[CV 5/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.573, test=0.577) total time=   1.3s\n",
      "[CV 3/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.590, test=0.576) total time=   2.1s\n",
      "[CV 1/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.805, test=0.528) total time=   2.6s\n",
      "[CV 4/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.765, test=0.741) total time=   3.2s\n",
      "[CV 5/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.766, test=0.722) total time=   2.8s\n",
      "[CV 3/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.758, test=0.707) total time=   2.2s\n",
      "[CV 4/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.755, test=0.730) total time=   3.8s\n",
      "[CV 2/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.778, test=0.627) total time=   2.7s\n",
      "[CV 2/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.781, test=0.619) total time=   3.1s\n",
      "[CV 5/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.754, test=0.717) total time=   3.8s\n",
      "[CV 5/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.751, test=0.719) total time=   2.8s\n",
      "[CV 3/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.749, test=0.695) total time=   2.1s\n",
      "[CV 4/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.750, test=0.725) total time=   3.1s\n",
      "[CV 2/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.757, test=0.620) total time=   2.5s\n",
      "[CV 3/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.728, test=0.679) total time=   2.6s\n",
      "[CV 1/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.772, test=0.523) total time=   2.2s\n",
      "[CV 2/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.756, test=0.625) total time=   3.0s\n",
      "[CV 5/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.728, test=0.699) total time=   3.7s\n",
      "[CV 1/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.775, test=0.527) total time=   3.3s\n",
      "[CV 2/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.626, test=0.534) total time=   1.3s\n",
      "[CV 4/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.587, test=0.591) total time=   1.8s\n",
      "[CV 3/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.588, test=0.580) total time=   1.4s\n",
      "[CV 1/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.618, test=0.538) total time=   1.0s\n",
      "[CV 2/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.585, test=0.550) total time=   1.4s\n",
      "[CV 5/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.587, test=0.582) total time=   2.0s\n",
      "[CV 2/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.589, test=0.553) total time=   2.3s\n",
      "[CV 5/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.581, test=0.581) total time=   1.4s\n",
      "[CV 3/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.592, test=0.584) total time=   2.5s\n",
      "[CV 2/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.586, test=0.548) total time=   2.7s\n",
      "[CV 5/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.585, test=0.584) total time=   2.5s\n",
      "[CV 5/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.581, test=0.586) total time=   2.0s\n",
      "[CV 3/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.584, test=0.568) total time=   1.4s\n",
      "[CV 4/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.586, test=0.591) total time=   2.5s\n",
      "[CV 2/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.577, test=0.545) total time=   1.6s\n",
      "[CV 3/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.590, test=0.571) total time=   2.1s\n",
      "[CV 1/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.811, test=0.536) total time=   2.6s\n",
      "[CV 2/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.804, test=0.628) total time=   2.9s\n",
      "[CV 5/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.781, test=0.714) total time=   4.3s\n",
      "[CV 1/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.812, test=0.535) total time=   4.5s\n",
      "[CV 4/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.763, test=0.725) total time=   3.6s\n",
      "[CV 3/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.763, test=0.696) total time=   4.9s\n",
      "[CV 1/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.797, test=0.521) total time=   3.4s\n",
      "[CV 4/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.760, test=0.723) total time=   3.6s\n",
      "[CV 5/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.760, test=0.722) total time=   2.3s\n",
      "[CV 3/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.752, test=0.684) total time=   2.1s\n",
      "[CV 4/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.754, test=0.722) total time=   3.6s\n",
      "[CV 2/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.765, test=0.620) total time=   3.0s\n",
      "[CV 3/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.725, test=0.686) total time=   4.4s\n",
      "[CV 1/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.771, test=0.535) total time=   2.2s\n",
      "[CV 1/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.771, test=0.542) total time=   2.6s\n",
      "[CV 4/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.731, test=0.709) total time=   3.2s\n",
      "[CV 1/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.771, test=0.533) total time=   3.9s\n",
      "[CV 4/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.586, test=0.592) total time=   1.6s\n",
      "[CV 5/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.584, test=0.579) total time=   1.8s\n",
      "[CV 3/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.581, test=0.573) total time=   1.3s\n",
      "[CV 5/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.584, test=0.579) total time=   1.8s\n",
      "[CV 3/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.580, test=0.569) total time=   1.3s\n",
      "[CV 4/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.590, test=0.596) total time=   1.8s\n",
      "[CV 1/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.617, test=0.538) total time=   1.4s\n",
      "[CV 2/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.589, test=0.556) total time=   2.0s\n",
      "[CV 5/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.581, test=0.579) total time=   2.8s\n",
      "[CV 5/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.584, test=0.580) total time=   2.7s\n",
      "[CV 3/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.580, test=0.568) total time=   1.6s\n",
      "[CV 4/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.596) total time=   1.9s\n",
      "[CV 2/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.582, test=0.546) total time=   1.4s\n",
      "[CV 3/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.576) total time=   2.0s\n",
      "[CV 1/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.619, test=0.534) total time=   1.5s\n",
      "[CV 2/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.589, test=0.552) total time=   2.2s\n",
      "[CV 5/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.580, test=0.575) total time=   2.1s\n",
      "[CV 1/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.626, test=0.536) total time=   2.1s\n",
      "[CV 4/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.765, test=0.740) total time=   1.9s\n",
      "[CV 2/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.798, test=0.626) total time=   3.2s\n",
      "[CV 5/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.760, test=0.726) total time=   2.1s\n",
      "[CV 3/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.764, test=0.694) total time=   3.7s\n",
      "[CV 2/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.781, test=0.625) total time=   3.6s\n",
      "[CV 5/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.757, test=0.729) total time=   4.3s\n",
      "[CV 1/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.791, test=0.536) total time=   3.9s\n",
      "[CV 4/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.747, test=0.728) total time=   2.3s\n",
      "[CV 2/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.783, test=0.627) total time=   3.5s\n",
      "[CV 5/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.745, test=0.714) total time=   2.2s\n",
      "[CV 3/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.751, test=0.692) total time=   4.0s\n",
      "[CV 2/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.756, test=0.625) total time=   2.7s\n",
      "[CV 5/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.728, test=0.699) total time=   3.7s\n",
      "[CV 1/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.775, test=0.527) total time=   3.5s\n",
      "[CV 4/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.728, test=0.715) total time=   2.2s\n",
      "[CV 2/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.760, test=0.619) total time=   3.2s\n",
      "[CV 5/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.576, test=0.582) total time=   1.4s\n",
      "[CV 3/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.589, test=0.581) total time=   3.0s\n",
      "[CV 1/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.624, test=0.539) total time=   2.1s\n",
      "[CV 5/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.582, test=0.582) total time=   2.7s\n",
      "[CV 4/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.780, test=0.734) total time=   2.8s\n",
      "[CV 1/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.809, test=0.534) total time=   2.6s\n",
      "[CV 3/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.771, test=0.708) total time=   3.4s\n",
      "[CV 1/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.804, test=0.535) total time=   3.0s\n",
      "[CV 1/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.804, test=0.541) total time=   4.7s\n",
      "[CV 4/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.762, test=0.724) total time=   4.4s\n",
      "[CV 5/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.760, test=0.722) total time=   3.6s\n",
      "[CV 3/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.755, test=0.690) total time=   1.9s\n",
      "[CV 4/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.759, test=0.728) total time=   2.5s\n",
      "[CV 2/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.785, test=0.620) total time=   1.9s\n",
      "[CV 3/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.755, test=0.691) total time=   3.6s\n",
      "[CV 1/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.771, test=0.535) total time=   2.9s\n",
      "[CV 1/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.771, test=0.542) total time=   4.6s\n",
      "[CV 4/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.731, test=0.709) total time=   3.5s\n",
      "[CV 4/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.728, test=0.711) total time=   2.6s\n",
      "[CV 3/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.725, test=0.683) total time=   1.9s\n",
      "[CV 4/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.728, test=0.711) total time=   3.2s\n",
      "[CV 2/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.581, test=0.553) total time=   1.7s\n",
      "[CV 2/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.558) total time=   2.0s\n",
      "[CV 5/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.582, test=0.580) total time=   2.3s\n",
      "[CV 1/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.626, test=0.536) total time=   2.3s\n",
      "[CV 4/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.586, test=0.592) total time=   1.4s\n",
      "[CV 2/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.558) total time=   2.3s\n",
      "[CV 5/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.576, test=0.574) total time=   1.3s\n",
      "[CV 3/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.593, test=0.580) total time=   2.9s\n",
      "[CV 1/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.624, test=0.540) total time=   2.4s\n",
      "[CV 5/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.581, test=0.579) total time=   2.8s\n",
      "[CV 1/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.624, test=0.538) total time=   2.3s\n",
      "[CV 4/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.580, test=0.590) total time=   1.5s\n",
      "[CV 2/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.591, test=0.556) total time=   2.5s\n",
      "[CV 5/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.573, test=0.577) total time=   1.8s\n",
      "[CV 3/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.590, test=0.576) total time=   2.1s\n",
      "[CV 2/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.589, test=0.552) total time=   1.7s\n",
      "[CV 5/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.580, test=0.575) total time=   2.1s\n",
      "[CV 4/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.767, test=0.745) total time=   2.6s\n",
      "[CV 1/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.798, test=0.525) total time=   2.0s\n",
      "[CV 2/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.798, test=0.622) total time=   2.9s\n",
      "[CV 4/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.763, test=0.735) total time=   3.8s\n",
      "[CV 1/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.797, test=0.531) total time=   4.6s\n",
      "[CV 4/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.747, test=0.728) total time=   2.4s\n",
      "[CV 2/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.783, test=0.627) total time=   3.9s\n",
      "[CV 1/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.792, test=0.524) total time=   3.0s\n",
      "[CV 4/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.749, test=0.725) total time=   3.5s\n",
      "[CV 5/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.746, test=0.718) total time=   3.0s\n",
      "[CV 3/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.724, test=0.682) total time=   2.5s\n",
      "[CV 4/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.727, test=0.717) total time=   2.5s\n",
      "[CV 2/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.757, test=0.620) total time=   2.3s\n",
      "[CV 3/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.728, test=0.679) total time=   3.0s\n",
      "[CV 1/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.772, test=0.523) total time=   2.3s\n",
      "[CV 5/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.723, test=0.689) total time=   2.3s\n",
      "[CV 3/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.727, test=0.678) total time=   2.8s\n",
      "[CV 5/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.584, test=0.580) total time=   2.3s\n",
      "[CV 3/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.581, test=0.568) total time=   1.6s\n",
      "[CV 4/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.596) total time=   2.7s\n",
      "[CV 2/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.584, test=0.547) total time=   1.7s\n",
      "[CV 3/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.586, test=0.576) total time=   1.9s\n",
      "[CV 1/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.619, test=0.534) total time=   1.4s\n",
      "[CV 2/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.589, test=0.552) total time=   2.0s\n",
      "[CV 5/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.580, test=0.575) total time=   2.5s\n",
      "[CV 1/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.626, test=0.536) total time=   2.3s\n",
      "[CV 4/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.580, test=0.590) total time=   1.3s\n",
      "[CV 2/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.591, test=0.556) total time=   2.1s\n",
      "[CV 5/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.771, test=0.728) total time=   2.0s\n",
      "[CV 3/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.768, test=0.701) total time=   3.2s\n",
      "[CV 1/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.800, test=0.522) total time=   2.9s\n",
      "[CV 5/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.768, test=0.719) total time=   3.8s\n",
      "[CV 5/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.758, test=0.731) total time=   3.7s\n",
      "[CV 3/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.753, test=0.706) total time=   2.5s\n",
      "[CV 5/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.751, test=0.719) total time=   3.1s\n",
      "[CV 2/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.778, test=0.627) total time=   2.4s\n",
      "[CV 3/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.752, test=0.691) total time=   3.0s\n",
      "[CV 1/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.788, test=0.530) total time=   2.1s\n",
      "[CV 3/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.752, test=0.691) total time=   3.0s\n",
      "[CV 5/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.748, test=0.718) total time=   4.1s\n",
      "[CV 1/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.775, test=0.527) total time=   3.4s\n",
      "[CV 4/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.728, test=0.715) total time=   2.4s\n",
      "[CV 3/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.727, test=0.678) total time=   3.4s\n",
      "[CV 1/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.774, test=0.534) total time=   3.0s\n",
      "[CV 4/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.727, test=0.715) total time=   2.2s\n",
      "[CV 5/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.584, test=0.584) total time=   1.4s\n",
      "[CV 3/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.583, test=0.573) total time=   1.1s\n",
      "[CV 1/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.626, test=0.533) total time=   1.8s\n",
      "[CV 4/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.584, test=0.594) total time=   1.0s\n",
      "[CV 2/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.550) total time=   1.7s\n",
      "[CV 5/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.581, test=0.581) total time=   1.4s\n",
      "[CV 3/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.592, test=0.584) total time=   2.3s\n",
      "[CV 1/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.624, test=0.539) total time=   2.0s\n",
      "[CV 4/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.587, test=0.593) total time=   2.6s\n",
      "[CV 5/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.585, test=0.590) total time=   2.4s\n",
      "[CV 3/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.584, test=0.568) total time=   1.5s\n",
      "[CV 4/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.586, test=0.591) total time=   2.1s\n",
      "[CV 2/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.577, test=0.545) total time=   1.5s\n",
      "[CV 3/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.590, test=0.571) total time=   2.5s\n",
      "[CV 5/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.582, test=0.582) total time=   2.5s\n",
      "[CV 1/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.627, test=0.535) total time=   2.8s\n",
      "[CV 4/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.780, test=0.732) total time=   2.1s\n",
      "[CV 2/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.804, test=0.625) total time=   3.9s\n",
      "[CV 5/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.775, test=0.724) total time=   2.5s\n",
      "[CV 3/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.774, test=0.703) total time=   4.7s\n",
      "[CV 2/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.793, test=0.620) total time=   4.6s\n",
      "[CV 1/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.800, test=0.521) total time=   2.9s\n",
      "[CV 5/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.753, test=0.719) total time=   2.2s\n",
      "[CV 3/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.759, test=0.699) total time=   3.7s\n",
      "[CV 2/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.787, test=0.628) total time=   2.5s\n",
      "[CV 5/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.760, test=0.719) total time=   3.4s\n",
      "[CV 1/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.796, test=0.529) total time=   4.9s\n",
      "[CV 4/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.723, test=0.703) total time=   2.7s\n",
      "[CV 2/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.764, test=0.617) total time=   4.9s\n",
      "[CV 5/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.729, test=0.699) total time=   1.9s\n",
      "[CV 3/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.725, test=0.679) total time=   3.0s\n",
      "[CV 1/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.771, test=0.542) total time=   3.1s\n",
      "[CV 4/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.731, test=0.709) total time=   3.5s\n",
      "[CV 1/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.626, test=0.536) total time=   2.3s\n",
      "[CV 5/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.575, test=0.571) total time=   1.4s\n",
      "[CV 2/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.592, test=0.558) total time=   2.3s\n",
      "[CV 2/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.557) total time=   1.9s\n",
      "[CV 5/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.581, test=0.581) total time=   2.2s\n",
      "[CV 1/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.625, test=0.541) total time=   2.9s\n",
      "[CV 4/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.583, test=0.594) total time=   1.7s\n",
      "[CV 2/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.591, test=0.561) total time=   3.3s\n",
      "[CV 5/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.576, test=0.573) total time=   1.5s\n",
      "[CV 3/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.591, test=0.577) total time=   2.3s\n",
      "[CV 1/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.624, test=0.544) total time=   2.0s\n",
      "[CV 4/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.585, test=0.594) total time=   2.5s\n",
      "[CV 5/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.580, test=0.579) total time=   1.8s\n",
      "[CV 3/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.579, test=0.569) total time=   1.3s\n",
      "[CV 4/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.585, test=0.597) total time=   1.7s\n",
      "[CV 2/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.794, test=0.616) total time=   1.9s\n",
      "[CV 5/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.770, test=0.726) total time=   2.6s\n",
      "[CV 3/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.761, test=0.692) total time=   1.9s\n",
      "[CV 4/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.766, test=0.742) total time=   2.9s\n",
      "[CV 2/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.781, test=0.622) total time=   2.2s\n",
      "[CV 3/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.756, test=0.705) total time=   3.6s\n",
      "[CV 1/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.791, test=0.521) total time=   2.7s\n",
      "[CV 5/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.751, test=0.726) total time=   2.3s\n",
      "[CV 3/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.752, test=0.685) total time=   3.9s\n",
      "[CV 2/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.781, test=0.619) total time=   3.0s\n",
      "[CV 5/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.754, test=0.717) total time=   3.5s\n",
      "[CV 1/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.790, test=0.531) total time=   3.8s\n",
      "[CV 4/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.728, test=0.715) total time=   2.4s\n",
      "[CV 2/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.760, test=0.619) total time=   3.4s\n",
      "[CV 5/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.723, test=0.689) total time=   2.4s\n",
      "[CV 2/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.760, test=0.619) total time=   3.5s\n",
      "[CV 2/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.756, test=0.625) total time=   3.0s\n",
      "[CV 5/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.728, test=0.699) total time=   2.2s\n"
     ]
    }
   ],
   "source": [
    "#set the high-parameter\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [75, 100, 125],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_depth': [5, 10],\n",
    "    'max_features': ['sqrt']  # round(sqrt(#cols))\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "\n",
    "# Disable tqdm progress bar and set mininterval to suppress messages\n",
    "with tqdm(total=600, mininterval=1e-9) as pbar:\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=5, return_train_score=True,\n",
    "                               n_jobs=-1, verbose=20, scoring=kappa_scorer)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    pbar.update()  # Make sure progress bar completes\n",
    "\n",
    "# Enable warnings again\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "grid_search.best_params_  # To check the best set of parameters returned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b8ab3-9434-48be-b49b-4325ea087102",
   "metadata": {},
   "source": [
    "##### The parameter {'criterion': 'gini','max_depth': 10, 'max_features': 'sqrt','min_samples_leaf': 1, 'min_samples_split': 2,'n_estimators': 75} was chosen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a5c47-a8ca-4ee4-ac13-1f455cb75641",
   "metadata": {},
   "source": [
    "####  Cross validation socre - Kappa-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b36fd1f9-04f4-4607-8eb5-2ed0149c4638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RF: 0.3651125230787691 (0.24735472028529065)\n"
     ]
    }
   ],
   "source": [
    "rf1= RandomForestClassifier(criterion= 'gini',\n",
    " max_depth= 10,\n",
    " max_features= 'sqrt',\n",
    " min_samples_leaf= 1,\n",
    " min_samples_split= 2,\n",
    " n_estimators= 75)\n",
    "\n",
    "results = []\n",
    "kfold = KFold(n_splits=10, shuffle=False)\n",
    "cv_results = cross_val_score(rf1, X_train, y_train, cv=kfold, scoring=kappa_scorer)\n",
    "\n",
    "results.append(cv_results)\n",
    "    \n",
    "msg = f\" RF: {cv_results.mean()} ({cv_results.std()})\"\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122df32c-53aa-4c1a-8d19-2a3a7741fb08",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Variable Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb6fb112-d892-48f2-ac1e-fa5778da4086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train2 = X_train.copy()  \n",
    "y_train2 = y_train.copy()\n",
    "\n",
    "\n",
    "\n",
    "rf_tuned = rf1.fit(X_train2, y_train2)\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "# Calculate permutation feature importances\n",
    "result = permutation_importance(rf_tuned, X_train2, y_train2, n_repeats=10, random_state=42)\n",
    "\n",
    "# Sort and display the results\n",
    "feature_importances = pd.Series(result.importances_mean, index=X_train2.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.barplot(x=feature_importances, y=feature_importances.index)\n",
    "plt.xlabel('Significance Score Of Variables')\n",
    "plt.ylabel('Variables')\n",
    "plt.title(\"Variable Importance for Random Forest Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6eb0a110-004b-4e56-83d7-2636bbb08190",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_charges</th>\n",
       "      <td>0.075484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_charges</th>\n",
       "      <td>0.037760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>online_security</th>\n",
       "      <td>0.032651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contract_Two year</th>\n",
       "      <td>0.029746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contract_Month-to-month</th>\n",
       "      <td>0.027518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "total_charges            0.075484\n",
       "monthly_charges          0.037760\n",
       "online_security          0.032651\n",
       "contract_Two year        0.029746\n",
       "contract_Month-to-month  0.027518"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_df = pd.DataFrame(feature_importances)\n",
    "feature_importances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "282dbe1d-24fc-4cb8-83c0-15fe067227ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Significance Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_charges</th>\n",
       "      <td>0.075484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_charges</th>\n",
       "      <td>0.037760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Significance Score\n",
       "total_charges              0.075484\n",
       "monthly_charges            0.037760"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_df = feature_importances_df.rename(columns={0:'Significance Score'})\n",
    "feature_importances_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0459fb88-fc90-4677-a42e-31a15d1ece86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv('../data/Significant_Score/SMOTE_RF_Significance_Score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df103946-37a9-4ff4-81c2-8753018f3c0b",
   "metadata": {},
   "source": [
    "### the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f82adb6-e5f2-49a1-809a-2b1aa6f32eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[793, 240],\n",
       "       [108, 266]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "y_pred = rf1.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bd022fe-7ab5-4b1e-a934-504efd5e9eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    901\n",
       "1    506\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "\n",
    "y_pred_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f88d3bc0-37b2-4c79-8b12-540fc39a9cda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0        1033\n",
       "1         374\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "y_test_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88c07c97-4d20-4993-9028-7ede012a7c06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.752665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.525692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.711230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.604545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kappa</td>\n",
       "      <td>0.430439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Score\n",
       "0   Accuracy  0.752665\n",
       "1  Precision  0.525692\n",
       "2     Recall  0.711230\n",
       "3   F1-Score  0.604545\n",
       "4      Kappa  0.430439"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "\n",
    "y_pred = rf1.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Kappa\"],\n",
    "    \"Score\": [accuracy, precision, recall, f1, kappa]\n",
    "})\n",
    "\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1409e717-5d11-49f4-9267-9b9e45f5ba7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df.to_csv('../data/metrics/SMOTE_rf_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7ce82-7840-43b3-ac41-61001701f4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project_env",
   "language": "python",
   "name": "final_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
