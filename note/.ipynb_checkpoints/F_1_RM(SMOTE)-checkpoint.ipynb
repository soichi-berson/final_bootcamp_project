{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d0fa4e-7bde-483b-9bc5-cadc093e3eb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# # 6_1_Tuning parameters of RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947610f6-0840-44e2-853c-3df88906505f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4946b4fd-f093-4e80-966e-7997f9232fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load the files\n",
    "\n",
    "X_train = pd.read_csv('../data/x_y_data/SMOTE/X_resampled.csv')\n",
    "y_train = pd.read_csv('../data/x_y_data/SMOTE/y_resampled.csv')\n",
    "X_test = pd.read_csv('../data/x_y_data/SMOTE/X_test.csv')\n",
    "y_test = pd.read_csv('../data/x_y_data/SMOTE/y_test.csv')\n",
    "data = pd.read_csv('../data/cleaned_data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b770e0-43fd-405f-a0f3-a82d2d3bc83c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "1    4130\n",
       "0    4130\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.loc[y_train['churn'] == 'Yes', 'churn'] = 1\n",
    "y_train.loc[y_train['churn'] == 'No', 'churn'] = 0\n",
    "y_train['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3e4ed0-83ac-43ee-93ef-4074bd5fd44a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['churn'] =y_train['churn'].astype('int64')\n",
    "y_train['churn'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0552de7-37c5-40af-97ab-3519b92c31c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0    1033\n",
       "1     374\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.loc[y_test['churn'] == 'Yes', 'churn'] = 1\n",
    "y_test.loc[y_test['churn'] == 'No', 'churn'] = 0\n",
    "y_test['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8101933-b182-4679-a4a9-a05c0b08f3cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['churn'] =y_test['churn'].astype('int64')\n",
    "y_test['churn'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c00c71c1-988a-4769-ba45-9130db4684b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439bb0a45da14812888acaf39458499c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.578, test=0.551) total time=   0.8s\n",
      "[CV 5/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.618, test=0.535) total time=   0.8s\n",
      "[CV 4/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.585, test=0.594) total time=   1.4s\n",
      "[CV 2/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.578, test=0.551) total time=   1.2s\n",
      "[CV 5/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.584, test=0.584) total time=   1.4s\n",
      "[CV 3/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.587, test=0.567) total time=   1.0s\n",
      "[CV 4/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.594) total time=   1.4s\n",
      "[CV 2/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.579, test=0.545) total time=   1.1s\n",
      "[CV 3/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.590, test=0.582) total time=   1.9s\n",
      "[CV 1/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.617, test=0.538) total time=   1.4s\n",
      "[CV 2/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.588, test=0.548) total time=   2.0s\n",
      "[CV 5/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.586, test=0.584) total time=   2.6s\n",
      "[CV 1/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.627, test=0.533) total time=   2.9s\n",
      "[CV 4/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.583, test=0.596) total time=   1.9s\n",
      "[CV 2/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.588, test=0.552) total time=   2.4s\n",
      "[CV 5/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.579, test=0.580) total time=   0.9s\n",
      "[CV 3/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.593, test=0.580) total time=   1.8s\n",
      "[CV 1/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.626, test=0.534) total time=   1.5s\n",
      "[CV 4/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.587, test=0.591) total time=   1.6s\n",
      "[CV 5/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.585, test=0.586) total time=   1.4s\n",
      "[CV 3/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.586, test=0.573) total time=   1.2s\n",
      "[CV 4/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.586, test=0.592) total time=   1.9s\n",
      "[CV 2/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.579, test=0.545) total time=   1.3s\n",
      "[CV 3/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.590, test=0.582) total time=   2.0s\n",
      "[CV 1/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.618, test=0.538) total time=   1.6s\n",
      "[CV 5/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.581, test=0.584) total time=   1.7s\n",
      "[CV 3/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.593, test=0.584) total time=   2.8s\n",
      "[CV 2/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.547) total time=   2.3s\n",
      "[CV 5/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.582, test=0.582) total time=   2.3s\n",
      "[CV 1/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.627, test=0.535) total time=   3.1s\n",
      "[CV 4/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.583, test=0.596) total time=   1.6s\n",
      "[CV 2/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.588, test=0.552) total time=   2.8s\n",
      "[CV 5/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.778, test=0.736) total time=   2.2s\n",
      "[CV 3/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.778, test=0.705) total time=   4.0s\n",
      "[CV 1/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.814, test=0.535) total time=   3.4s\n",
      "[CV 4/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.772, test=0.731) total time=   5.4s\n",
      "[CV 5/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.583, test=0.575) total time=   0.8s\n",
      "[CV 1/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.626, test=0.533) total time=   1.8s\n",
      "[CV 5/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.579, test=0.580) total time=   1.1s\n",
      "[CV 3/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.593, test=0.584) total time=   1.7s\n",
      "[CV 1/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.625, test=0.536) total time=   1.4s\n",
      "[CV 4/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.587, test=0.592) total time=   1.9s\n",
      "[CV 5/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.585, test=0.585) total time=   1.9s\n",
      "[CV 3/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.586, test=0.573) total time=   1.3s\n",
      "[CV 4/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.586, test=0.592) total time=   2.0s\n",
      "[CV 2/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.579, test=0.546) total time=   1.6s\n",
      "[CV 3/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.594, test=0.580) total time=   2.5s\n",
      "[CV 1/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.617, test=0.535) total time=   1.5s\n",
      "[CV 5/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.576, test=0.582) total time=   1.7s\n",
      "[CV 3/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.589, test=0.581) total time=   2.4s\n",
      "[CV 1/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.624, test=0.539) total time=   2.5s\n",
      "[CV 4/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.586, test=0.592) total time=   2.6s\n",
      "[CV 5/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.581, test=0.586) total time=   2.0s\n",
      "[CV 3/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.776, test=0.706) total time=   2.2s\n",
      "[CV 1/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.811, test=0.533) total time=   3.9s\n",
      "[CV 4/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.772, test=0.730) total time=   2.6s\n",
      "[CV 2/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.796, test=0.632) total time=   4.5s\n",
      "[CV 5/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.763, test=0.731) total time=   3.5s\n",
      "[CV 2/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.795, test=0.630) total time=   5.0s\n",
      "[CV 2/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.787, test=0.628) total time=   3.4s\n",
      "[CV 5/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.760, test=0.719) total time=   3.5s\n",
      "[CV 1/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.798, test=0.525) total time=   2.9s\n",
      "[CV 4/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.752, test=0.728) total time=   2.5s\n",
      "[CV 2/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.789, test=0.622) total time=   4.6s\n",
      "[CV 5/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.729, test=0.699) total time=   2.8s\n",
      "[CV 3/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.725, test=0.679) total time=   4.6s\n",
      "[CV 2/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.762, test=0.625) total time=   2.6s\n",
      "[CV 5/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.729, test=0.705) total time=   3.2s\n",
      "[CV 5/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.730, test=0.702) total time=   3.1s\n",
      "[CV 3/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.581, test=0.573) total time=   1.6s\n",
      "[CV 3/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.579) total time=   1.9s\n",
      "[CV 1/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.616, test=0.536) total time=   1.4s\n",
      "[CV 1/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.626, test=0.538) total time=   1.9s\n",
      "[CV 4/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.591, test=0.599) total time=   2.3s\n",
      "[CV 5/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.592, test=0.582) total time=   1.3s\n",
      "[CV 1/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.618, test=0.535) total time=   1.1s\n",
      "[CV 4/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.583, test=0.594) total time=   1.1s\n",
      "[CV 2/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.590, test=0.554) total time=   1.7s\n",
      "[CV 5/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.580, test=0.585) total time=   1.0s\n",
      "[CV 3/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.594, test=0.582) total time=   1.7s\n",
      "[CV 2/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.588, test=0.548) total time=   1.9s\n",
      "[CV 5/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.586, test=0.584) total time=   2.2s\n",
      "[CV 1/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.629, test=0.534) total time=   2.6s\n",
      "[CV 4/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.584, test=0.592) total time=   1.7s\n",
      "[CV 2/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.548) total time=   2.9s\n",
      "[CV 1/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.624, test=0.539) total time=   2.3s\n",
      "[CV 4/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.586, test=0.592) total time=   2.3s\n",
      "[CV 5/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.581, test=0.586) total time=   2.5s\n",
      "[CV 3/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.584, test=0.568) total time=   1.6s\n",
      "[CV 4/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.586, test=0.591) total time=   2.1s\n",
      "[CV 2/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.799, test=0.626) total time=   2.5s\n",
      "[CV 5/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.779, test=0.724) total time=   2.9s\n",
      "[CV 3/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.768, test=0.707) total time=   2.5s\n",
      "[CV 4/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.771, test=0.726) total time=   3.4s\n",
      "[CV 2/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.792, test=0.623) total time=   3.3s\n",
      "[CV 3/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.761, test=0.705) total time=   4.5s\n",
      "[CV 5/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.768, test=0.724) total time=   4.3s\n",
      "[CV 1/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.798, test=0.525) total time=   4.3s\n",
      "[CV 4/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.756, test=0.731) total time=   2.0s\n",
      "[CV 2/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.785, test=0.628) total time=   2.9s\n",
      "[CV 5/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.753, test=0.717) total time=   2.8s\n",
      "[CV 3/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.755, test=0.690) total time=   4.6s\n",
      "[CV 2/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.762, test=0.625) total time=   4.5s\n",
      "[CV 5/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.729, test=0.705) total time=   3.6s\n",
      "[CV 1/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.771, test=0.533) total time=   3.1s\n",
      "[CV 4/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.723, test=0.703) total time=   2.0s\n",
      "[CV 2/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.764, test=0.617) total time=   3.7s\n",
      "[CV 1/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.626, test=0.538) total time=   2.0s\n",
      "[CV 4/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.591, test=0.599) total time=   2.3s\n",
      "[CV 4/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.590, test=0.594) total time=   1.8s\n",
      "[CV 2/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.584, test=0.547) total time=   1.4s\n",
      "[CV 3/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 1/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 1/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.583, test=0.594) total time=   0.9s\n",
      "[CV 2/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.590, test=0.556) total time=   1.8s\n",
      "[CV 2/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.589, test=0.552) total time=   1.5s\n",
      "[CV 5/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.588, test=0.580) total time=   1.6s\n",
      "[CV 1/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.627, test=0.531) total time=   1.7s\n",
      "[CV 4/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.585, test=0.597) total time=   1.3s\n",
      "[CV 1/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.629, test=0.534) total time=   2.4s\n",
      "[CV 4/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.585, test=0.597) total time=   1.4s\n",
      "[CV 2/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.589, test=0.553) total time=   2.6s\n",
      "[CV 1/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.624, test=0.536) total time=   2.7s\n",
      "[CV 4/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.588, test=0.594) total time=   2.5s\n",
      "[CV 1/5; 21/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 21/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.627, test=0.535) total time=   2.3s\n",
      "[CV 4/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.583, test=0.596) total time=   1.4s\n",
      "[CV 2/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.588, test=0.552) total time=   3.1s\n",
      "[CV 5/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.576, test=0.582) total time=   1.6s\n",
      "[CV 3/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.581) total time=   2.7s\n",
      "[CV 1/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.813, test=0.528) total time=   3.0s\n",
      "[CV 4/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.778, test=0.738) total time=   4.0s\n",
      "[CV 5/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.776, test=0.729) total time=   3.2s\n",
      "[CV 3/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.759, test=0.706) total time=   3.3s\n",
      "[CV 4/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.763, test=0.719) total time=   4.4s\n",
      "[CV 2/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.786, test=0.630) total time=   2.5s\n",
      "[CV 3/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.757, test=0.696) total time=   3.3s\n",
      "[CV 1/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.800, test=0.521) total time=   2.3s\n",
      "[CV 1/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.797, test=0.521) total time=   2.6s\n",
      "[CV 4/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.760, test=0.723) total time=   3.3s\n",
      "[CV 5/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.758, test=0.723) total time=   3.6s\n",
      "[CV 3/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.725, test=0.683) total time=   2.8s\n",
      "[CV 4/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.728, test=0.711) total time=   4.5s\n",
      "[CV 2/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.765, test=0.620) total time=   2.2s\n",
      "[CV 3/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.725, test=0.686) total time=   2.5s\n",
      "[CV 1/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.771, test=0.535) total time=   1.9s\n",
      "[CV 2/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.762, test=0.625) total time=   3.2s\n",
      "[CV 5/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.729, test=0.705) total time=   3.5s\n",
      "[CV 2/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.593, test=0.556) total time=   2.3s\n",
      "[CV 4/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.586, test=0.592) total time=   1.4s\n",
      "[CV 3/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.592, test=0.581) total time=   2.2s\n",
      "[CV 1/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.625, test=0.539) total time=   1.9s\n",
      "[CV 4/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.596) total time=   2.2s\n",
      "[CV 5/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 75}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.586, test=0.574) total time=   1.9s\n",
      "[CV 2/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.584, test=0.551) total time=   1.4s\n",
      "[CV 1/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.624, test=0.540) total time=   2.0s\n",
      "[CV 4/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.587, test=0.596) total time=   2.9s\n",
      "[CV 1/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.625, test=0.541) total time=   3.3s\n",
      "[CV 4/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.583, test=0.594) total time=   1.6s\n",
      "[CV 2/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.558) total time=   2.3s\n",
      "[CV 5/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.573, test=0.577) total time=   1.5s\n",
      "[CV 3/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.590, test=0.576) total time=   2.5s\n",
      "[CV 1/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.624, test=0.544) total time=   2.3s\n",
      "[CV 4/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.585, test=0.594) total time=   2.1s\n",
      "[CV 5/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.580, test=0.579) total time=   1.7s\n",
      "[CV 3/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.762, test=0.701) total time=   2.0s\n",
      "[CV 1/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.805, test=0.529) total time=   3.3s\n",
      "[CV 4/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.763, test=0.740) total time=   2.1s\n",
      "[CV 1/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.801, test=0.528) total time=   3.7s\n",
      "[CV 5/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.753, test=0.728) total time=   2.7s\n",
      "[CV 2/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.782, test=0.633) total time=   4.5s\n",
      "[CV 1/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.792, test=0.524) total time=   3.1s\n",
      "[CV 1/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.791, test=0.521) total time=   2.3s\n",
      "[CV 5/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.751, test=0.726) total time=   2.3s\n",
      "[CV 3/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.752, test=0.685) total time=   3.5s\n",
      "[CV 1/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.790, test=0.525) total time=   3.0s\n",
      "[CV 4/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.750, test=0.728) total time=   4.1s\n",
      "[CV 5/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.727, test=0.696) total time=   2.6s\n",
      "[CV 3/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.724, test=0.682) total time=   2.4s\n",
      "[CV 4/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.727, test=0.717) total time=   2.8s\n",
      "[CV 2/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.757, test=0.620) total time=   2.2s\n",
      "[CV 3/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.728, test=0.679) total time=   2.9s\n",
      "[CV 2/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.589, test=0.552) total time=   1.3s\n",
      "[CV 5/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.588, test=0.580) total time=   1.8s\n",
      "[CV 4/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.585, test=0.594) total time=   1.4s\n",
      "[CV 2/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.578, test=0.545) total time=   1.0s\n",
      "[CV 3/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.591, test=0.582) total time=   1.4s\n",
      "[CV 1/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.617, test=0.538) total time=   1.1s\n",
      "[CV 1/5; 11/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 11/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.624, test=0.539) total time=   1.9s\n",
      "[CV 4/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.587, test=0.593) total time=   2.2s\n",
      "[CV 5/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.585, test=0.585) total time=   2.0s\n",
      "[CV 3/5; 16/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 16/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.587, test=0.568) total time=   1.7s\n",
      "[CV 4/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.592) total time=   2.5s\n",
      "[CV 2/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.577, test=0.545) total time=   1.6s\n",
      "[CV 3/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.590, test=0.571) total time=   2.2s\n",
      "[CV 1/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.617, test=0.535) total time=   1.5s\n",
      "[CV 2/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.547) total time=   2.6s\n",
      "[CV 1/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.617, test=0.535) total time=   1.6s\n",
      "[CV 2/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.547) total time=   2.1s\n",
      "[CV 4/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.586, test=0.592) total time=   2.7s\n",
      "[CV 3/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.778, test=0.705) total time=   2.9s\n",
      "[CV 2/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.795, test=0.627) total time=   2.5s\n",
      "[CV 2/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.794, test=0.626) total time=   3.4s\n",
      "[CV 5/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.776, test=0.718) total time=   5.5s\n",
      "[CV 1/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.804, test=0.542) total time=   5.4s\n",
      "[CV 4/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.756, test=0.731) total time=   2.1s\n",
      "[CV 2/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.785, test=0.628) total time=   4.2s\n",
      "[CV 5/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.753, test=0.719) total time=   1.9s\n",
      "[CV 3/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.759, test=0.699) total time=   3.0s\n",
      "[CV 2/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.784, test=0.611) total time=   3.7s\n",
      "[CV 5/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.758, test=0.724) total time=   4.9s\n",
      "[CV 1/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.771, test=0.533) total time=   5.1s\n",
      "[CV 4/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.723, test=0.703) total time=   2.0s\n",
      "[CV 2/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.764, test=0.617) total time=   3.1s\n",
      "[CV 5/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.729, test=0.699) total time=   2.3s\n",
      "[CV 3/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.725, test=0.679) total time=   3.7s\n",
      "[CV 4/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.590, test=0.594) total time=   1.9s\n",
      "[CV 2/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.581, test=0.553) total time=   1.4s\n",
      "[CV 3/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.577) total time=   1.8s\n",
      "[CV 1/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.619, test=0.534) total time=   1.4s\n",
      "[CV 5/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.577, test=0.573) total time=   1.4s\n",
      "[CV 3/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.591, test=0.580) total time=   2.2s\n",
      "[CV 3/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.579) total time=   2.0s\n",
      "[CV 1/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.617, test=0.538) total time=   1.8s\n",
      "[CV 2/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.589, test=0.556) total time=   2.4s\n",
      "[CV 4/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.587, test=0.596) total time=   2.8s\n",
      "[CV 5/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.583, test=0.580) total time=   1.8s\n",
      "[CV 3/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.579, test=0.569) total time=   1.4s\n",
      "[CV 4/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.585, test=0.597) total time=   2.0s\n",
      "[CV 2/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.582, test=0.546) total time=   1.5s\n",
      "[CV 3/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.576) total time=   2.2s\n",
      "[CV 1/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.619, test=0.534) total time=   1.3s\n",
      "[CV 1/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.624, test=0.544) total time=   1.8s\n",
      "[CV 4/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.585, test=0.594) total time=   2.1s\n",
      "[CV 3/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.763, test=0.699) total time=   2.6s\n",
      "[CV 2/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.796, test=0.620) total time=   2.0s\n",
      "[CV 3/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.763, test=0.692) total time=   2.9s\n",
      "[CV 1/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.797, test=0.511) total time=   2.2s\n",
      "[CV 1/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.798, test=0.525) total time=   3.6s\n",
      "[CV 4/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.755, test=0.730) total time=   4.5s\n",
      "[CV 4/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.748, test=0.725) total time=   3.1s\n",
      "[CV 3/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.753, test=0.706) total time=   2.4s\n",
      "[CV 4/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.748, test=0.725) total time=   2.9s\n",
      "[CV 2/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.775, test=0.623) total time=   2.1s\n",
      "[CV 2/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.775, test=0.626) total time=   3.0s\n",
      "[CV 1/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.772, test=0.523) total time=   2.5s\n",
      "[CV 1/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.774, test=0.534) total time=   2.7s\n",
      "[CV 4/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.727, test=0.715) total time=   3.7s\n",
      "[CV 5/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.727, test=0.696) total time=   2.8s\n",
      "[CV 3/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.724, test=0.682) total time=   2.2s\n",
      "[CV 4/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.727, test=0.717) total time=   2.9s\n",
      "[CV 5/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.582, test=0.579) total time=   1.9s\n",
      "[CV 3/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.581, test=0.568) total time=   1.3s\n",
      "[CV 4/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.596) total time=   2.0s\n",
      "[CV 2/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.584, test=0.551) total time=   1.7s\n",
      "[CV 3/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.579) total time=   2.5s\n",
      "[CV 1/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.619, test=0.534) total time=   1.7s\n",
      "[CV 1/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.625, test=0.539) total time=   2.0s\n",
      "[CV 4/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.587, test=0.596) total time=   2.3s\n",
      "[CV 5/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.580, test=0.579) total time=   2.0s\n",
      "[CV 3/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.579, test=0.569) total time=   1.5s\n",
      "[CV 4/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.585, test=0.597) total time=   2.1s\n",
      "[CV 2/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.582, test=0.546) total time=   1.3s\n",
      "[CV 3/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.576) total time=   1.7s\n",
      "[CV 1/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.802, test=0.523) total time=   2.0s\n",
      "[CV 2/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.794, test=0.625) total time=   2.6s\n",
      "[CV 5/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.771, test=0.722) total time=   3.4s\n",
      "[CV 2/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.793, test=0.617) total time=   3.7s\n",
      "[CV 4/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.756, test=0.728) total time=   2.7s\n",
      "[CV 3/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.759, test=0.702) total time=   4.5s\n",
      "[CV 3/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.752, test=0.691) total time=   3.1s\n",
      "[CV 4/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.749, test=0.725) total time=   3.9s\n",
      "[CV 1/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.791, test=0.536) total time=   3.6s\n",
      "[CV 4/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.751, test=0.728) total time=   2.2s\n",
      "[CV 2/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.778, test=0.627) total time=   3.8s\n",
      "[CV 5/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.723, test=0.689) total time=   2.1s\n",
      "[CV 3/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.727, test=0.678) total time=   3.4s\n",
      "[CV 1/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.774, test=0.534) total time=   3.0s\n",
      "[CV 4/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.727, test=0.715) total time=   3.6s\n",
      "[CV 5/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.727, test=0.696) total time=   2.8s\n",
      "[CV 5/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.766, test=0.728) total time=   4.6s\n",
      "[CV 3/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.755, test=0.690) total time=   2.2s\n",
      "[CV 4/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.759, test=0.728) total time=   3.5s\n",
      "[CV 2/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.786, test=0.630) total time=   2.0s\n",
      "[CV 3/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.757, test=0.696) total time=   2.5s\n",
      "[CV 1/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.793, test=0.524) total time=   1.9s\n",
      "[CV 1/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.794, test=0.530) total time=   3.7s\n",
      "[CV 4/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.757, test=0.714) total time=   5.0s\n",
      "[CV 5/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.730, test=0.702) total time=   4.3s\n",
      "[CV 3/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.725, test=0.683) total time=   1.9s\n",
      "[CV 5/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.730, test=0.702) total time=   2.4s\n",
      "[CV 2/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.765, test=0.620) total time=   1.9s\n",
      "[CV 3/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.725, test=0.686) total time=   3.2s\n",
      "[CV 1/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.616, test=0.536) total time=   1.7s\n",
      "[CV 5/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.575, test=0.571) total time=   1.5s\n",
      "[CV 3/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.592, test=0.579) total time=   2.3s\n",
      "[CV 2/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.558) total time=   1.9s\n",
      "[CV 5/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.582, test=0.580) total time=   2.2s\n",
      "[CV 1/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.627, test=0.538) total time=   2.4s\n",
      "[CV 4/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.583, test=0.594) total time=   1.3s\n",
      "[CV 2/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.591, test=0.561) total time=   2.9s\n",
      "[CV 5/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.576, test=0.574) total time=   1.6s\n",
      "[CV 3/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.593, test=0.580) total time=   3.2s\n",
      "[CV 2/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.557) total time=   1.9s\n",
      "[CV 5/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.579, test=0.582) total time=   2.4s\n",
      "[CV 1/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.626, test=0.536) total time=   2.6s\n",
      "[CV 4/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.580, test=0.590) total time=   1.5s\n",
      "[CV 2/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.591, test=0.556) total time=   2.2s\n",
      "[CV 5/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.573, test=0.577) total time=   1.3s\n",
      "[CV 3/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.590, test=0.576) total time=   2.1s\n",
      "[CV 1/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.805, test=0.528) total time=   2.6s\n",
      "[CV 4/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.765, test=0.741) total time=   3.2s\n",
      "[CV 5/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.766, test=0.722) total time=   2.8s\n",
      "[CV 3/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.758, test=0.707) total time=   2.2s\n",
      "[CV 4/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.755, test=0.730) total time=   3.8s\n",
      "[CV 2/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.778, test=0.627) total time=   2.7s\n",
      "[CV 2/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.781, test=0.619) total time=   3.1s\n",
      "[CV 5/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.754, test=0.717) total time=   3.8s\n",
      "[CV 5/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.751, test=0.719) total time=   2.8s\n",
      "[CV 3/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.749, test=0.695) total time=   2.1s\n",
      "[CV 4/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.750, test=0.725) total time=   3.1s\n",
      "[CV 2/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.757, test=0.620) total time=   2.5s\n",
      "[CV 3/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.728, test=0.679) total time=   2.6s\n",
      "[CV 1/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.772, test=0.523) total time=   2.2s\n",
      "[CV 2/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.756, test=0.625) total time=   3.0s\n",
      "[CV 5/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.728, test=0.699) total time=   3.7s\n",
      "[CV 1/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.775, test=0.527) total time=   3.3s\n",
      "[CV 2/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=nan, test=nan) total time=   0.1s\n",
      "[CV 5/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5; 2/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.626, test=0.534) total time=   1.3s\n",
      "[CV 4/5; 3/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 3/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.587, test=0.591) total time=   1.8s\n",
      "[CV 3/5; 5/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 5/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.588, test=0.580) total time=   1.4s\n",
      "[CV 1/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.618, test=0.538) total time=   1.0s\n",
      "[CV 2/5; 8/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 8/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.585, test=0.550) total time=   1.4s\n",
      "[CV 5/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.587, test=0.582) total time=   2.0s\n",
      "[CV 2/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.589, test=0.553) total time=   2.3s\n",
      "[CV 5/5; 13/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 13/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.581, test=0.581) total time=   1.4s\n",
      "[CV 3/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.592, test=0.584) total time=   2.5s\n",
      "[CV 2/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.586, test=0.548) total time=   2.7s\n",
      "[CV 5/5; 18/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 18/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.585, test=0.584) total time=   2.5s\n",
      "[CV 5/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.581, test=0.586) total time=   2.0s\n",
      "[CV 3/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.584, test=0.568) total time=   1.4s\n",
      "[CV 4/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.586, test=0.591) total time=   2.5s\n",
      "[CV 2/5; 25/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 25/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.577, test=0.545) total time=   1.6s\n",
      "[CV 3/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.590, test=0.571) total time=   2.1s\n",
      "[CV 1/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.811, test=0.536) total time=   2.6s\n",
      "[CV 2/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.804, test=0.628) total time=   2.9s\n",
      "[CV 5/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.781, test=0.714) total time=   4.3s\n",
      "[CV 1/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.812, test=0.535) total time=   4.5s\n",
      "[CV 4/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.763, test=0.725) total time=   3.6s\n",
      "[CV 3/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.763, test=0.696) total time=   4.9s\n",
      "[CV 1/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.797, test=0.521) total time=   3.4s\n",
      "[CV 4/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.760, test=0.723) total time=   3.6s\n",
      "[CV 5/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.760, test=0.722) total time=   2.3s\n",
      "[CV 3/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.752, test=0.684) total time=   2.1s\n",
      "[CV 4/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.754, test=0.722) total time=   3.6s\n",
      "[CV 2/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.765, test=0.620) total time=   3.0s\n",
      "[CV 3/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.725, test=0.686) total time=   4.4s\n",
      "[CV 1/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.771, test=0.535) total time=   2.2s\n",
      "[CV 1/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.771, test=0.542) total time=   2.6s\n",
      "[CV 4/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.731, test=0.709) total time=   3.2s\n",
      "[CV 1/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.771, test=0.533) total time=   3.9s\n",
      "[CV 4/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.586, test=0.592) total time=   1.6s\n",
      "[CV 5/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.584, test=0.579) total time=   1.8s\n",
      "[CV 3/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.581, test=0.573) total time=   1.3s\n",
      "[CV 5/5; 59/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 59/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.584, test=0.579) total time=   1.8s\n",
      "[CV 3/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.580, test=0.569) total time=   1.3s\n",
      "[CV 4/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.590, test=0.596) total time=   1.8s\n",
      "[CV 1/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.617, test=0.538) total time=   1.4s\n",
      "[CV 2/5; 65/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.589, test=0.556) total time=   2.0s\n",
      "[CV 5/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.581, test=0.579) total time=   2.8s\n",
      "[CV 5/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.584, test=0.580) total time=   2.7s\n",
      "[CV 3/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.580, test=0.568) total time=   1.6s\n",
      "[CV 4/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.596) total time=   1.9s\n",
      "[CV 2/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.582, test=0.546) total time=   1.4s\n",
      "[CV 3/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 3/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.576) total time=   2.0s\n",
      "[CV 1/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.619, test=0.534) total time=   1.5s\n",
      "[CV 2/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.589, test=0.552) total time=   2.2s\n",
      "[CV 5/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.580, test=0.575) total time=   2.1s\n",
      "[CV 1/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.626, test=0.536) total time=   2.1s\n",
      "[CV 4/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.765, test=0.740) total time=   1.9s\n",
      "[CV 2/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.798, test=0.626) total time=   3.2s\n",
      "[CV 5/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.760, test=0.726) total time=   2.1s\n",
      "[CV 3/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.764, test=0.694) total time=   3.7s\n",
      "[CV 2/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.781, test=0.625) total time=   3.6s\n",
      "[CV 5/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.757, test=0.729) total time=   4.3s\n",
      "[CV 1/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.791, test=0.536) total time=   3.9s\n",
      "[CV 4/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.747, test=0.728) total time=   2.3s\n",
      "[CV 2/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.783, test=0.627) total time=   3.5s\n",
      "[CV 5/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.745, test=0.714) total time=   2.2s\n",
      "[CV 3/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.751, test=0.692) total time=   4.0s\n",
      "[CV 2/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.756, test=0.625) total time=   2.7s\n",
      "[CV 5/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.728, test=0.699) total time=   3.7s\n",
      "[CV 1/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.775, test=0.527) total time=   3.5s\n",
      "[CV 4/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.728, test=0.715) total time=   2.2s\n",
      "[CV 2/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.760, test=0.619) total time=   3.2s\n",
      "[CV 5/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.576, test=0.582) total time=   1.4s\n",
      "[CV 3/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.589, test=0.581) total time=   3.0s\n",
      "[CV 1/5; 26/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 26/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.624, test=0.539) total time=   2.1s\n",
      "[CV 5/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.582, test=0.582) total time=   2.7s\n",
      "[CV 4/5; 29/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 29/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.780, test=0.734) total time=   2.8s\n",
      "[CV 1/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.809, test=0.534) total time=   2.6s\n",
      "[CV 3/5; 32/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 32/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.771, test=0.708) total time=   3.4s\n",
      "[CV 1/5; 34/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 34/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.804, test=0.535) total time=   3.0s\n",
      "[CV 1/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.804, test=0.541) total time=   4.7s\n",
      "[CV 4/5; 36/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 36/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.762, test=0.724) total time=   4.4s\n",
      "[CV 5/5; 38/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 38/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.760, test=0.722) total time=   3.6s\n",
      "[CV 3/5; 40/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 40/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.755, test=0.690) total time=   1.9s\n",
      "[CV 4/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.759, test=0.728) total time=   2.5s\n",
      "[CV 2/5; 43/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 43/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.785, test=0.620) total time=   1.9s\n",
      "[CV 3/5; 44/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 44/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.755, test=0.691) total time=   3.6s\n",
      "[CV 1/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.771, test=0.535) total time=   2.9s\n",
      "[CV 1/5; 47/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 47/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.771, test=0.542) total time=   4.6s\n",
      "[CV 4/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.731, test=0.709) total time=   3.5s\n",
      "[CV 4/5; 50/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 50/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.728, test=0.711) total time=   2.6s\n",
      "[CV 3/5; 52/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 52/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.725, test=0.683) total time=   1.9s\n",
      "[CV 4/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.728, test=0.711) total time=   3.2s\n",
      "[CV 2/5; 55/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 55/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.581, test=0.553) total time=   1.7s\n",
      "[CV 2/5; 56/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 56/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.587, test=0.558) total time=   2.0s\n",
      "[CV 5/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.582, test=0.580) total time=   2.3s\n",
      "[CV 1/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.626, test=0.536) total time=   2.3s\n",
      "[CV 4/5; 61/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 61/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.586, test=0.592) total time=   1.4s\n",
      "[CV 2/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.558) total time=   2.3s\n",
      "[CV 5/5; 64/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 64/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.576, test=0.574) total time=   1.3s\n",
      "[CV 3/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.593, test=0.580) total time=   2.9s\n",
      "[CV 1/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.624, test=0.540) total time=   2.4s\n",
      "[CV 5/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.581, test=0.579) total time=   2.8s\n",
      "[CV 1/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.624, test=0.538) total time=   2.3s\n",
      "[CV 4/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.580, test=0.590) total time=   1.5s\n",
      "[CV 2/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.591, test=0.556) total time=   2.5s\n",
      "[CV 5/5; 76/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 76/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.573, test=0.577) total time=   1.8s\n",
      "[CV 3/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.590, test=0.576) total time=   2.1s\n",
      "[CV 2/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.589, test=0.552) total time=   1.7s\n",
      "[CV 5/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.580, test=0.575) total time=   2.1s\n",
      "[CV 4/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.767, test=0.745) total time=   2.6s\n",
      "[CV 1/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 1/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.798, test=0.525) total time=   2.0s\n",
      "[CV 2/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.798, test=0.622) total time=   2.9s\n",
      "[CV 4/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.763, test=0.735) total time=   3.8s\n",
      "[CV 1/5; 90/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 90/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.797, test=0.531) total time=   4.6s\n",
      "[CV 4/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.747, test=0.728) total time=   2.4s\n",
      "[CV 2/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.783, test=0.627) total time=   3.9s\n",
      "[CV 1/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.792, test=0.524) total time=   3.0s\n",
      "[CV 4/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.749, test=0.725) total time=   3.5s\n",
      "[CV 5/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.746, test=0.718) total time=   3.0s\n",
      "[CV 3/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.724, test=0.682) total time=   2.5s\n",
      "[CV 4/5; 101/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 101/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.727, test=0.717) total time=   2.5s\n",
      "[CV 2/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.757, test=0.620) total time=   2.3s\n",
      "[CV 3/5; 104/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 104/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.728, test=0.679) total time=   3.0s\n",
      "[CV 1/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.772, test=0.523) total time=   2.3s\n",
      "[CV 5/5; 106/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 106/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.723, test=0.689) total time=   2.3s\n",
      "[CV 3/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.727, test=0.678) total time=   2.8s\n",
      "[CV 5/5; 65/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.584, test=0.580) total time=   2.3s\n",
      "[CV 3/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.581, test=0.568) total time=   1.6s\n",
      "[CV 4/5; 68/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 68/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.587, test=0.596) total time=   2.7s\n",
      "[CV 2/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.584, test=0.547) total time=   1.7s\n",
      "[CV 3/5; 71/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 71/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.586, test=0.576) total time=   1.9s\n",
      "[CV 1/5; 73/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 73/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.619, test=0.534) total time=   1.4s\n",
      "[CV 2/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 2/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.589, test=0.552) total time=   2.0s\n",
      "[CV 5/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 5/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.580, test=0.575) total time=   2.5s\n",
      "[CV 1/5; 78/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 78/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.626, test=0.536) total time=   2.3s\n",
      "[CV 4/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.580, test=0.590) total time=   1.3s\n",
      "[CV 2/5; 81/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 81/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.591, test=0.556) total time=   2.1s\n",
      "[CV 5/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.771, test=0.728) total time=   2.0s\n",
      "[CV 3/5; 84/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 84/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.768, test=0.701) total time=   3.2s\n",
      "[CV 1/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.800, test=0.522) total time=   2.9s\n",
      "[CV 5/5; 87/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 87/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.768, test=0.719) total time=   3.8s\n",
      "[CV 5/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.758, test=0.731) total time=   3.7s\n",
      "[CV 3/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.753, test=0.706) total time=   2.5s\n",
      "[CV 5/5; 92/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 92/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=0.751, test=0.719) total time=   3.1s\n",
      "[CV 2/5; 94/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 94/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.778, test=0.627) total time=   2.4s\n",
      "[CV 3/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.752, test=0.691) total time=   3.0s\n",
      "[CV 1/5; 97/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 1/5; 97/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.788, test=0.530) total time=   2.1s\n",
      "[CV 3/5; 98/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 98/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.752, test=0.691) total time=   3.0s\n",
      "[CV 5/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.748, test=0.718) total time=   4.1s\n",
      "[CV 1/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.775, test=0.527) total time=   3.4s\n",
      "[CV 4/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.728, test=0.715) total time=   2.4s\n",
      "[CV 3/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.727, test=0.678) total time=   3.4s\n",
      "[CV 1/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.774, test=0.534) total time=   3.0s\n",
      "[CV 4/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.727, test=0.715) total time=   2.2s\n",
      "[CV 5/5; 2/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.584, test=0.584) total time=   1.4s\n",
      "[CV 3/5; 4/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 4/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.583, test=0.573) total time=   1.1s\n",
      "[CV 1/5; 6/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 1/5; 6/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.626, test=0.533) total time=   1.8s\n",
      "[CV 4/5; 7/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 4/5; 7/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.584, test=0.594) total time=   1.0s\n",
      "[CV 2/5; 9/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 2/5; 9/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.589, test=0.550) total time=   1.7s\n",
      "[CV 5/5; 10/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 10/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.581, test=0.581) total time=   1.4s\n",
      "[CV 3/5; 12/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 12/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.592, test=0.584) total time=   2.3s\n",
      "[CV 1/5; 14/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 1/5; 14/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.624, test=0.539) total time=   2.0s\n",
      "[CV 4/5; 15/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 4/5; 15/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.587, test=0.593) total time=   2.6s\n",
      "[CV 5/5; 17/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100\n",
      "[CV 5/5; 17/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.585, test=0.590) total time=   2.4s\n",
      "[CV 3/5; 19/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 3/5; 19/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.584, test=0.568) total time=   1.5s\n",
      "[CV 4/5; 20/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 4/5; 20/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.586, test=0.591) total time=   2.1s\n",
      "[CV 2/5; 22/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 2/5; 22/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.577, test=0.545) total time=   1.5s\n",
      "[CV 3/5; 23/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 3/5; 23/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.590, test=0.571) total time=   2.5s\n",
      "[CV 5/5; 24/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 24/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.582, test=0.582) total time=   2.5s\n",
      "[CV 1/5; 27/108] START criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 27/108] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.627, test=0.535) total time=   2.8s\n",
      "[CV 4/5; 28/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 28/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.780, test=0.732) total time=   2.1s\n",
      "[CV 2/5; 30/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 30/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.804, test=0.625) total time=   3.9s\n",
      "[CV 5/5; 31/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 31/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.775, test=0.724) total time=   2.5s\n",
      "[CV 3/5; 33/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 33/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.774, test=0.703) total time=   4.7s\n",
      "[CV 2/5; 35/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 35/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.793, test=0.620) total time=   4.6s\n",
      "[CV 1/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.800, test=0.521) total time=   2.9s\n",
      "[CV 5/5; 37/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 37/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.753, test=0.719) total time=   2.2s\n",
      "[CV 3/5; 39/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 39/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.759, test=0.699) total time=   3.7s\n",
      "[CV 2/5; 41/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 41/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.787, test=0.628) total time=   2.5s\n",
      "[CV 5/5; 42/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 42/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.760, test=0.719) total time=   3.4s\n",
      "[CV 1/5; 45/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 45/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.796, test=0.529) total time=   4.9s\n",
      "[CV 4/5; 46/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 46/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.723, test=0.703) total time=   2.7s\n",
      "[CV 2/5; 48/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 48/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.764, test=0.617) total time=   4.9s\n",
      "[CV 5/5; 49/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 49/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.729, test=0.699) total time=   1.9s\n",
      "[CV 3/5; 51/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 3/5; 51/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.725, test=0.679) total time=   3.0s\n",
      "[CV 1/5; 53/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 1/5; 53/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.771, test=0.542) total time=   3.1s\n",
      "[CV 4/5; 54/108] START criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 4/5; 54/108] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.731, test=0.709) total time=   3.5s\n",
      "[CV 1/5; 57/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 57/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=(train=0.626, test=0.536) total time=   2.3s\n",
      "[CV 5/5; 58/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 58/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.575, test=0.571) total time=   1.4s\n",
      "[CV 2/5; 60/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 60/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=125;, score=(train=0.592, test=0.558) total time=   2.3s\n",
      "[CV 2/5; 62/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 62/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.587, test=0.557) total time=   1.9s\n",
      "[CV 5/5; 63/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 63/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=(train=0.581, test=0.581) total time=   2.2s\n",
      "[CV 1/5; 66/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 1/5; 66/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.625, test=0.541) total time=   2.9s\n",
      "[CV 4/5; 67/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75\n",
      "[CV 4/5; 67/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=75;, score=(train=0.583, test=0.594) total time=   1.7s\n",
      "[CV 2/5; 69/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 69/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.591, test=0.561) total time=   3.3s\n",
      "[CV 5/5; 70/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75\n",
      "[CV 5/5; 70/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=75;, score=(train=0.576, test=0.573) total time=   1.5s\n",
      "[CV 3/5; 72/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 3/5; 72/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.591, test=0.577) total time=   2.3s\n",
      "[CV 1/5; 74/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100\n",
      "[CV 1/5; 74/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=(train=0.624, test=0.544) total time=   2.0s\n",
      "[CV 4/5; 75/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 4/5; 75/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.585, test=0.594) total time=   2.5s\n",
      "[CV 5/5; 77/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100\n",
      "[CV 5/5; 77/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=100;, score=(train=0.580, test=0.579) total time=   1.8s\n",
      "[CV 3/5; 79/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75\n",
      "[CV 3/5; 79/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=75;, score=(train=0.579, test=0.569) total time=   1.3s\n",
      "[CV 4/5; 80/108] START criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 4/5; 80/108] END criterion=entropy, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.585, test=0.597) total time=   1.7s\n",
      "[CV 2/5; 82/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75\n",
      "[CV 2/5; 82/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=75;, score=(train=0.794, test=0.616) total time=   1.9s\n",
      "[CV 5/5; 83/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100\n",
      "[CV 5/5; 83/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=0.770, test=0.726) total time=   2.6s\n",
      "[CV 3/5; 85/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75\n",
      "[CV 3/5; 85/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=75;, score=(train=0.761, test=0.692) total time=   1.9s\n",
      "[CV 4/5; 86/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100\n",
      "[CV 4/5; 86/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=100;, score=(train=0.766, test=0.742) total time=   2.9s\n",
      "[CV 2/5; 88/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75\n",
      "[CV 2/5; 88/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=75;, score=(train=0.781, test=0.622) total time=   2.2s\n",
      "[CV 3/5; 89/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100\n",
      "[CV 3/5; 89/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.756, test=0.705) total time=   3.6s\n",
      "[CV 1/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 1/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.791, test=0.521) total time=   2.7s\n",
      "[CV 5/5; 91/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75\n",
      "[CV 5/5; 91/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=75;, score=(train=0.751, test=0.726) total time=   2.3s\n",
      "[CV 3/5; 93/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125\n",
      "[CV 3/5; 93/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=(train=0.752, test=0.685) total time=   3.9s\n",
      "[CV 2/5; 95/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100\n",
      "[CV 2/5; 95/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=(train=0.781, test=0.619) total time=   3.0s\n",
      "[CV 5/5; 96/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125\n",
      "[CV 5/5; 96/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=125;, score=(train=0.754, test=0.717) total time=   3.5s\n",
      "[CV 1/5; 99/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125\n",
      "[CV 1/5; 99/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=125;, score=(train=0.790, test=0.531) total time=   3.8s\n",
      "[CV 4/5; 100/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75\n",
      "[CV 4/5; 100/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=75;, score=(train=0.728, test=0.715) total time=   2.4s\n",
      "[CV 2/5; 102/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125\n",
      "[CV 2/5; 102/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=(train=0.760, test=0.619) total time=   3.4s\n",
      "[CV 5/5; 103/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75\n",
      "[CV 5/5; 103/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=75;, score=(train=0.723, test=0.689) total time=   2.4s\n",
      "[CV 2/5; 105/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125\n",
      "[CV 2/5; 105/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=125;, score=(train=0.760, test=0.619) total time=   3.5s\n",
      "[CV 2/5; 107/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100\n",
      "[CV 2/5; 107/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=(train=0.756, test=0.625) total time=   3.0s\n",
      "[CV 5/5; 108/108] START criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125\n",
      "[CV 5/5; 108/108] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=(train=0.728, test=0.699) total time=   2.2s\n"
     ]
    }
   ],
   "source": [
    "#set the high-parameter\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [75, 100, 125],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_depth': [5, 10],\n",
    "    'max_features': ['sqrt']  # round(sqrt(#cols))\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "\n",
    "# Disable tqdm progress bar and set mininterval to suppress messages\n",
    "with tqdm(total=600, mininterval=1e-9) as pbar:\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=5, return_train_score=True,\n",
    "                               n_jobs=-1, verbose=20, scoring=kappa_scorer)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    pbar.update()  # Make sure progress bar completes\n",
    "\n",
    "# Enable warnings again\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "grid_search.best_params_  # To check the best set of parameters returned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b8ab3-9434-48be-b49b-4325ea087102",
   "metadata": {},
   "source": [
    "##### The parameter {'criterion': 'gini','max_depth': 10, 'max_features': 'sqrt','min_samples_leaf': 1, 'min_samples_split': 2,'n_estimators': 75} was chosen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a5c47-a8ca-4ee4-ac13-1f455cb75641",
   "metadata": {},
   "source": [
    "####  Cross validation socre - Kappa-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b36fd1f9-04f4-4607-8eb5-2ed0149c4638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/soichirotanabe/Desktop/IRONHACK/Week_9/Final_project/final_project_env/lib/python3.11/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RF: 0.3651125230787691 (0.24735472028529065)\n"
     ]
    }
   ],
   "source": [
    "rf1= RandomForestClassifier(criterion= 'gini',\n",
    " max_depth= 10,\n",
    " max_features= 'sqrt',\n",
    " min_samples_leaf= 1,\n",
    " min_samples_split= 2,\n",
    " n_estimators= 75)\n",
    "\n",
    "results = []\n",
    "kfold = KFold(n_splits=10, shuffle=False)\n",
    "cv_results = cross_val_score(rf1, X_train, y_train, cv=kfold, scoring=kappa_scorer)\n",
    "\n",
    "results.append(cv_results)\n",
    "    \n",
    "msg = f\" RF: {cv_results.mean()} ({cv_results.std()})\"\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122df32c-53aa-4c1a-8d19-2a3a7741fb08",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Variable Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb6fb112-d892-48f2-ac1e-fa5778da4086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train2 = X_train.copy()  \n",
    "y_train2 = y_train.copy()\n",
    "\n",
    "rf1= RandomForestClassifier(criterion= 'gini',\n",
    " max_depth= 10,\n",
    " max_features= 'sqrt',\n",
    " min_samples_leaf= 1,\n",
    " min_samples_split= 2,\n",
    " n_estimators= 75)\n",
    "\n",
    "rf_tuned = rf1.fit(X_train2, y_train2)\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "# Calculate permutation feature importances\n",
    "result = permutation_importance(rf_tuned, X_train2, y_train2, n_repeats=10, random_state=42)\n",
    "\n",
    "# Sort and display the results\n",
    "feature_importances = pd.Series(result.importances_mean, index=X_train2.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.barplot(x=feature_importances, y=feature_importances.index)\n",
    "plt.xlabel('Significance Score Of Variables')\n",
    "plt.ylabel('Variables')\n",
    "plt.title(\"Variable Importance for Random Forest Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb0a110-004b-4e56-83d7-2636bbb08190",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_charges</th>\n",
       "      <td>0.079225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>online_security</th>\n",
       "      <td>0.030714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_charges</th>\n",
       "      <td>0.029879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech_support</th>\n",
       "      <td>0.024867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contract_Month-to-month</th>\n",
       "      <td>0.023063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "total_charges            0.079225\n",
       "online_security          0.030714\n",
       "monthly_charges          0.029879\n",
       "tech_support             0.024867\n",
       "contract_Month-to-month  0.023063"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_df = pd.DataFrame(feature_importances)\n",
    "feature_importances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "282dbe1d-24fc-4cb8-83c0-15fe067227ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Significance Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_charges</th>\n",
       "      <td>0.075484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_charges</th>\n",
       "      <td>0.037760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Significance Score\n",
       "total_charges              0.075484\n",
       "monthly_charges            0.037760"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_df = feature_importances_df.rename(columns={0:'Significance Score'})\n",
    "feature_importances_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0459fb88-fc90-4677-a42e-31a15d1ece86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_importances_df.T.to_csv('../data/Significant_Score/T_SMOTE_RF_Significance_Score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df103946-37a9-4ff4-81c2-8753018f3c0b",
   "metadata": {},
   "source": [
    "### the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f82adb6-e5f2-49a1-809a-2b1aa6f32eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[793, 240],\n",
       "       [108, 266]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "y_pred = rf1.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bd022fe-7ab5-4b1e-a934-504efd5e9eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    901\n",
       "1    506\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "\n",
    "y_pred_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f88d3bc0-37b2-4c79-8b12-540fc39a9cda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0        1033\n",
       "1         374\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "y_test_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88c07c97-4d20-4993-9028-7ede012a7c06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.752665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.525692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.711230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.604545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kappa</td>\n",
       "      <td>0.430439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Score\n",
       "0   Accuracy  0.752665\n",
       "1  Precision  0.525692\n",
       "2     Recall  0.711230\n",
       "3   F1-Score  0.604545\n",
       "4      Kappa  0.430439"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "\n",
    "y_pred = rf1.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Kappa\"],\n",
    "    \"Score\": [accuracy, precision, recall, f1, kappa]\n",
    "})\n",
    "\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1409e717-5d11-49f4-9267-9b9e45f5ba7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df.to_csv('../data/metrics/SMOTE_rf_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7ce82-7840-43b3-ac41-61001701f4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project_env",
   "language": "python",
   "name": "final_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
